# --- Install compatible versions, then force a Colab runtime restart ---
!pip install -q numpy==1.24.4 pandas==1.5.3 scikit-learn==1.3.2 joblib==1.3.2

# Force a clean restart so compiled extensions load against the new NumPy
import os, sys
os.kill(os.getpid(), 9)


# =======================
# Imports (after restart)
# =======================
import io, sys, os, math
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
import joblib

IN_COLAB = "google.colab" in sys.modules
if IN_COLAB:
    from google.colab import files

# =======================
# Load data
# =======================
RAW_URL = "https://raw.githubusercontent.com/code-red-Marshall/Car-Price-Predictor/main/Cleaned_Car_data.csv"

def load_dataset():
    try:
        print("Trying to load dataset from GitHub raw URL...")
        df = pd.read_csv(RAW_URL)
        print("Loaded dataset from GitHub.")
        return df
    except Exception as e:
        print("GitHub load failed:", e)

    if os.path.exists("Cleaned_Car_data.csv"):
        print("Found local Cleaned_Car_data.csv.")
        return pd.read_csv("Cleaned_Car_data.csv")

    if IN_COLAB:
        print("Please upload Cleaned_Car_data.csv")
        uploaded = files.upload()
        key = next(iter(uploaded.keys()))
        return pd.read_csv(io.BytesIO(uploaded[key]))

    raise FileNotFoundError("Could not load Cleaned_Car_data.csv")

df = load_dataset()
print("Shape:", df.shape)
print("Columns:", list(df.columns))

# =======================
# Check/clean columns
# =======================
REQ_FEATS = ["company", "name", "year", "kms_driven", "fuel_type"]
TARGET_CANDIDATES = ["price", "Price", "selling_price", "Selling_Price", "sellingPrice"]

target_col = next((c for c in TARGET_CANDIDATES if c in df.columns), None)
if target_col is None:
    raise ValueError(f"Target column not found. Expected one of: {TARGET_CANDIDATES}")

missing = [c for c in REQ_FEATS if c not in df.columns]
if missing:
    raise ValueError("Missing required feature columns: " + ", ".join(missing))

df = df[REQ_FEATS + [target_col]].copy()

# numeric clean
for col in ["year", "kms_driven"]:
    df[col] = (
        df[col].astype(str)
        .str.replace(",", "", regex=False)
        .str.strip()
        .replace(["", "nan", "NaN", "None"], np.nan)
    )
    df[col] = pd.to_numeric(df[col], errors="coerce")

# categorical clean
for col in ["company", "name", "fuel_type"]:
    df[col] = df[col].astype(str).str.strip()

# target clean
df[target_col] = (
    df[target_col].astype(str)
    .str.replace(",", "", regex=False)
    .str.strip()
    .replace(["", "nan", "NaN", "None"], np.nan)
)
df[target_col] = pd.to_numeric(df[target_col], errors="coerce")

before = len(df)
df = df.dropna(subset=REQ_FEATS + [target_col])
print(f"Dropped {before - len(df)} rows with missing values. Final rows: {len(df)}")

# =======================
# Split
# =======================
X = df[REQ_FEATS]
y = df[target_col].astype(float)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# =======================
# Pipeline: preprocess + LinearRegression
# =======================
num_cols = ["year", "kms_driven"]
cat_cols = ["company", "name", "fuel_type"]

preprocess = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(with_mean=False), num_cols),
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols),
    ],
    remainder="drop",
    sparse_threshold=1.0,
)

pipe = Pipeline([
    ("preprocess", preprocess),
    ("model", LinearRegression()),
])

# =======================
# Train & evaluate
# =======================
pipe.fit(X_train, y_train)
preds = pipe.predict(X_test)
rmse = math.sqrt(mean_squared_error(y_test, preds))
r2 = r2_score(y_test, preds)
print("\n=== Evaluation ===")
print(f"RMSE: {rmse:,.2f}")
print(f"R^2:  {r2:.4f}")

# =======================
# Save model
# =======================
OUT = "LRModel.pkl"
joblib.dump(pipe, OUT)
print(f"Saved: {OUT}")

if IN_COLAB:
    files.download(OUT)

